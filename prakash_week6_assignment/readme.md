
---

## ğŸ“ Quick Overview

This assignment demonstrates:

- âœ… Secure data movement from local servers using **Self-hosted Integration Runtime (SHIR)**  
- ğŸ“‚ Integration of **FTP/SFTP data sources** into Azure Data Factory  
- ğŸ” Building **incremental data pipelines** with **daily automation**  
- ğŸ“† Configuring **monthly triggers** for the last Saturday of the month  
- ğŸ”„ Implementing **retry logic** for transient failure recovery  

These components together form the foundation of reliable and scalable cloud-based data workflows in modern data engineering.

---

## ğŸ“„ Solution Files

| File Name         | Description |
|------------------|-------------|
| [`solution1.md`](solution1.md) | Configure Self-hosted Integration Runtime and load data from a local server into Azure SQL Database. |
| [`solution2.md`](solution2.md) | Set up FTP/SFTP connection and create a pipeline to extract data in ADF. |
| [`solution3.md`](solution3.md) | Design an incremental data load pipeline with watermarking/change tracking and daily automation. |
| [`solution4.md`](solution4.md) | Automate a pipeline to trigger on the last Saturday of every month using custom time-based triggers. |
| [`solution5.md`](solution5.md) | Implement retry logic to handle transient failures during data extraction and processing. |

---

Feel free to explore each file for detailed implementation steps and explanations.

## ğŸ‘¨â€ğŸ’» Author

**Prakash Pandey**  
ğŸ“§ [LinkedIn](https://www.linkedin.com/in/prakash-pandey-2827522b1/)  
ğŸ› ï¸ GitHub: [@prakashpandey16](https://github.com/prakashpandey16)

